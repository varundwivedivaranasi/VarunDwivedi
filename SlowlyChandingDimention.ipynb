{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "809e891d-56f4-49da-81a5-8272e3cb1f25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, current_date\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SCD-Example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Initial customer dimension\n",
    "data_initial = [\n",
    "    (1, \"Alice\",   \"100 Main St\"),\n",
    "    (2, \"Bob\",     \"200 Oak Ave\"),\n",
    "    (3, \"Charlie\", \"300 Pine Rd\")\n",
    "]\n",
    "cols = [\"cust_id\", \"name\", \"address\"]\n",
    "\n",
    "df_dim = spark.createDataFrame(data_initial, cols)\n",
    "\n",
    "# Incoming updates\n",
    "# - Alice moved\n",
    "# - Bob unchanged\n",
    "# - New customer Dana\n",
    "data_updates = [\n",
    "    (1, \"Alice\",   \"123 Elm St\"),\n",
    "    (2, \"Bob\",     \"200 Oak Ave\"),\n",
    "    (4, \"Dana\",    \"400 Birch Blvd\")\n",
    "]\n",
    "df_updates = spark.createDataFrame(data_updates, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d32c3e63-58bb-4ecc-b937-b77ca08200c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import coalesce\n",
    "\n",
    "# 1. Overwrite existing records\n",
    "df_scd1_updated = df_dim.alias(\"d\") \\\n",
    "    .join(df_updates.alias(\"u\"), \"cust_id\", \"left\") \\\n",
    "    .select(\n",
    "        \"cust_id\",\n",
    "        coalesce(\"u.name\", \"d.name\").alias(\"name\"),\n",
    "        coalesce(\"u.address\", \"d.address\").alias(\"address\")\n",
    "    ).filter(\"u.cust_id IS NOT NULL\")\n",
    "df_scd1_updated.display()\n",
    "# 2. Append truly new customers\n",
    "new_customers = df_updates \\\n",
    "    .join(df_dim, \"cust_id\", \"left_anti\")\n",
    "new_customers.display()\n",
    "df_scd1 = df_scd1_updated.unionByName(new_customers)\n",
    "\n",
    "df_scd1.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a24edc8-3b6d-4dcd-8835-bb2e5b8272ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "# Add SCD2 metadata to the existing dimension\n",
    "df_dim2 = df_dim \\\n",
    "    .withColumn(\"effective_date\", to_date(lit(\"2023-01-01\"))) \\\n",
    "    .withColumn(\"end_date\", lit(None).cast(\"date\")) \\\n",
    "    .withColumn(\"is_current\", lit(True))\n",
    "\n",
    "df_dim2.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bc5b99c-b4a0-4ad5-9fc9-9f4dad29f35d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join to spot updates vs unchanged vs new\n",
    "df_join = df_dim2.alias(\"d\") \\\n",
    "    .join(df_updates.alias(\"u\"), \"cust_id\", \"right\")\n",
    "df_join.display()\n",
    "# Rows needing new version: changed values OR brand new cust_id\n",
    "from pyspark.sql.functions import expr, col\n",
    "\n",
    "df_changed = df_join \\\n",
    "    .filter((expr(\"d.name <> u.name\")) | (expr(\"d.address <> u.address\")) | (col(\"d.cust_id\").isNull())) \\\n",
    "    .select(\"u.cust_id\", \"u.name\", \"u.address\")\n",
    "\n",
    "display(df_changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5761aac0-5e5e-4e3a-bff2-a42b404b366e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_add\n",
    "\n",
    "# 1. Expire old versions for changed rows\n",
    "df_expired = df_dim2.alias(\"d\") \\\n",
    "    .join(df_changed.alias(\"c\"), \"cust_id\") \\\n",
    "    .select(\n",
    "        \"d.cust_id\", \"d.name\", \"d.address\", \"d.effective_date\",\n",
    "        date_add(current_date(), -1).alias(\"end_date\"),\n",
    "        lit(False).alias(\"is_current\")\n",
    "    )\n",
    "df_expired.display()\n",
    "# 2. New current versions\n",
    "df_new_versions = df_changed \\\n",
    "    .withColumn(\"effective_date\", current_date()) \\\n",
    "    .withColumn(\"end_date\", lit(None).cast(\"date\")) \\\n",
    "    .withColumn(\"is_current\", lit(True))\n",
    "df_new_versions.display()\n",
    "# 3. Keep unaffected current rows\n",
    "df_unchanged = df_dim2.filter(~df_dim2.cust_id.isin([r.cust_id for r in df_changed.collect()]))\n",
    "df_unchanged.display()\n",
    "# 4. Union all to get the full SCD2 dimension\n",
    "df_scd2 = df_expired.unionByName(df_new_versions).unionByName(df_unchanged)\n",
    "\n",
    "df_scd2.orderBy(\"cust_id\", \"effective_date\").display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "SlowlyChandingDimention",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
