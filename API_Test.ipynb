{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07dc1324-e4d7-42d5-a609-aa52f4b3abf5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    DoubleType,\n",
    "    BooleanType\n",
    ")\n",
    "\n",
    "# Step 1: Authenticate and get token\n",
    "auth_url = \"https://dummyjson.com/auth/login\"\n",
    "credentials = {\n",
    "    \"username\": \"kminchelle\",\n",
    "    \"password\": \"0lelplR\"\n",
    "}\n",
    "auth_response = requests.post(auth_url, json=credentials)\n",
    "access_token = auth_response.json().get(\"token\")\n",
    "print(access_token)\n",
    "# Step 2: Fetch protected data\n",
    "headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "print(headers)\n",
    "data_url = \"https://dummyjson.com/products\"\n",
    "data_response = requests.get(data_url, headers=headers)\n",
    "data_json = data_response.json()[\"products\"]\n",
    "\n",
    "# Step 3: Define schema to resolve type conflicts\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"description\", StringType(), True),\n",
    "    StructField(\"price\", IntegerType(), True),\n",
    "    StructField(\"discountPercentage\", DoubleType(), True),\n",
    "    StructField(\"rating\", DoubleType(), True),\n",
    "    StructField(\"stock\", IntegerType(), True),\n",
    "    StructField(\"brand\", StringType(), True),\n",
    "    StructField(\"category\", StringType(), True),\n",
    "    StructField(\"thumbnail\", StringType(), True),\n",
    "    StructField(\"images\", \n",
    "        # ArrayType is not imported, so treat as StringType for simplicity\n",
    "        StringType(), True\n",
    "    )\n",
    "])\n",
    "\n",
    "# Step 4: Load into PySpark DataFrame with schema\n",
    "df = spark.createDataFrame(data_json, schema=schema)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63dbf0ff-af77-4afd-b135-9def4b9e2108",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# main.py\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType,\n",
    "    IntegerType, DoubleType\n",
    ")\n",
    "import requests\n",
    "\n",
    "class APIClient:\n",
    "    def __init__(self, config):\n",
    "        self.auth_url = config[\"auth_url\"]\n",
    "        self.credentials = config[\"credentials\"]\n",
    "        self.data_url = config[\"data_url\"]\n",
    "        self.token = None\n",
    "\n",
    "    def authenticate(self):\n",
    "        \"\"\"Authenticate and store the access token.\"\"\"\n",
    "        response = requests.post(self.auth_url, json=self.credentials)\n",
    "        self.token = response.json().get(\"token\")\n",
    "        return self.token\n",
    "\n",
    "    def fetch_data(self):\n",
    "        \"\"\"Fetch data from the API using the stored token.\"\"\"\n",
    "        if not self.token:\n",
    "            self.authenticate()\n",
    "        headers = {\"Authorization\": f\"Bearer {self.token}\"}\n",
    "        response = requests.get(self.data_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json().get(\"products\", [])\n",
    "CONFIG = {\n",
    "    \"auth_url\": \"https://dummyjson.com/auth/login\",\n",
    "    \"credentials\": {\n",
    "        \"username\": \"kminchelle\",\n",
    "        \"password\": \"0lelplR\"\n",
    "    },\n",
    "    \"data_url\": \"https://dummyjson.com/products\"\n",
    "}\n",
    "\n",
    "SCHEMA = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"description\", StringType(), True),\n",
    "    StructField(\"price\", IntegerType(), True),\n",
    "    StructField(\"discountPercentage\", DoubleType(), True),\n",
    "    StructField(\"rating\", DoubleType(), True),\n",
    "    StructField(\"stock\", IntegerType(), True),\n",
    "    StructField(\"brand\", StringType(), True),\n",
    "    StructField(\"category\", StringType(), True),\n",
    "    StructField(\"thumbnail\", StringType(), True),\n",
    "    StructField(\"images\", StringType(), True)  # simplified\n",
    "])\n",
    "# Spark session\n",
    "spark = SparkSession.builder.appName(\"API Data Loader\").getOrCreate()\n",
    "\n",
    "# Create API client and fetch data\n",
    "client = APIClient(CONFIG)\n",
    "products_data = client.fetch_data()\n",
    "\n",
    "# Load into DataFrame\n",
    "df = spark.createDataFrame(products_data, schema=SCHEMA)\n",
    "df.display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "API_Test",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
